{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< [Notebook 14](PartIV3.ipynb) | [PyFinLab Index](ALWAYS-START-HERE.ipynb) | [Notebook 16](PartV2.ipynb) >\n",
    "\n",
    "<a id = \"ref00\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><img src=\"figures/UUBS.png\" width=\"180\" height=\"180\" border=\"10\" /></a>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 15: Multiple linear regression\n",
    "\n",
    "In this notebook we build and test a multiple linear regression prediction model for the next-day opening price of the SPY[ETF], based on historical data from a global range of stock markets. This is the first and most critical step in the process of building a signal-based trading model for the SPY[ETF], which will be the subject of the final video and notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Importing data into seperate data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Ordinary(Australia)\n",
    "aord = pd.read_csv('data/indexdata/ALLOrdinary.csv').set_index('Date')\n",
    "# Nikkei(Japan)\n",
    "nikkei = pd.read_csv('data/indexdata/Nikkei225.csv').set_index('Date')\n",
    "# Hang Seng(Hong Kong)\n",
    "hsi = pd.read_csv('data/indexdata/HSI.csv').set_index('Date')\n",
    "# Dax(Germany)\n",
    "daxi = pd.read_csv('data/indexdata/DAXI.csv').set_index('Date')\n",
    "# CAC40(France)\n",
    "cac40 = pd.read_csv('data/indexdata/CAC40.csv').set_index('Date')\n",
    "# Standard and Poor's(US)\n",
    "sp500 = pd.read_csv('data/indexdata/SP500.csv').set_index('Date')\n",
    "# Dow Jones(US)\n",
    "dji = pd.read_csv('data/indexdata/DJI.csv').set_index('Date')\n",
    "# Nasdaq(US)\n",
    "nasdaq = pd.read_csv('data/indexdata/NASDAQ_composite.csv').set_index('Date')\n",
    "# SPY[ETF](US)\n",
    "spy = pd.read_csv('data/indexdata/SPY.csv').set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to time-zone differences, we extract appropriate stock\n",
    "# market data for analysis. \n",
    "\n",
    "# Indexpanel is the DataFrame for our trading model.\n",
    "Indexpanel = pd.DataFrame(index=spy.index)\n",
    "\n",
    "# SPY[ETF]\n",
    "Indexpanel['spy']=spy['Open'].shift(-1)-spy['Open']\n",
    "Indexpanel['spy_lag1']=Indexpanel['spy'].shift(1)\n",
    "# US Market\n",
    "Indexpanel['sp500']=sp500[\"Open\"]-sp500['Open'].shift(1)\n",
    "Indexpanel['nasdaq']=nasdaq['Open']-nasdaq['Open'].shift(1)\n",
    "Indexpanel['dji']=dji['Open']-dji['Open'].shift(1)\n",
    "# European Markets\n",
    "Indexpanel['cac40']=cac40['Open']-cac40['Open'].shift(1)\n",
    "Indexpanel['daxi']=daxi['Open']-daxi['Open'].shift(1)\n",
    "# Asian/Australian Markets\n",
    "Indexpanel['aord']=aord['Close']-aord['Open']\n",
    "Indexpanel['hsi']=hsi['Close']-hsi['Open']\n",
    "Indexpanel['nikkei']=nikkei['Close']-nikkei['Open']\n",
    "# used for paper trading in next video\n",
    "Indexpanel['Price']=spy['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Indexpanel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's check to see if we have NaN values in Indexpanel\n",
    "Indexpanel.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the DataFrame method .fillna() to forward fill \n",
    "# the Nan values. We can then drop any remaining Nan values\n",
    "\n",
    "Indexpanel = Indexpanel.fillna(method='ffill')\n",
    "Indexpanel = Indexpanel.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see if we have any Nan values in Indexpanel now...\n",
    "Indexpanel.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our Indexpanel data frame object to CSV for later use\n",
    "Indexpanel.to_csv('data/indexdata/Indexpanel.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Indexpanel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Splitting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into non-overlapping training and test sets\n",
    "\n",
    "Train = Indexpanel.iloc[-2000:-1000, :]\n",
    "Test = Indexpanel.iloc[-1000:, :]\n",
    "print(Train.shape, Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Exploring the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate a scatter matrix across all stock markets \n",
    "# (and the price of SPY) to observe the association\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "sm = scatter_matrix(Train,figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Check the correlation of each index with spy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the indices with the strongest association\n",
    "corr_array = Train.iloc[:, :-1].corr()['spy']\n",
    "print(corr_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fit multiple linear regression model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'spy~spy_lag1+sp500+nasdaq+dji+cac40+daxi+aord+hsi+nikkei'\n",
    "lm = smf.ols(formula=formula, data=Train).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigating multicollinearity in predictors which 'failed' the p-value test\n",
    "Train.iloc[:,:-1].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['PredictedY'] = lm.predict(Train)\n",
    "Test['PredictedY'] = lm.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Train['spy'], Train['PredictedY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Model evaluation - statistical standards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure the performance of our model using some statistical metrics: \n",
    "<br>\n",
    "**RMSE** and **Adjusted** $R^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our own Python function to calulate the\n",
    "# RMSE(Root Mean Squared Error) and Adjusted R-squared\n",
    "def adjustedMetrics(data,model,model_k,yname):\n",
    "    data['yhat'] = model.predict(data)\n",
    "    SST = ((data[yname]-data[yname].mean())**2).sum()\n",
    "    SSR = ((data['yhat']-data[yname].mean())**2).sum()\n",
    "    SSE = ((data[yname]-data['yhat'])**2).sum()\n",
    "    r2 = SSR/SST\n",
    "    adjRsquared = 1-(1-r2)*(data.shape[0]-1)/(data.shape[0]-model_k-1)\n",
    "    RMSE = (SSE/(data.shape[0]-model_k-1))**0.5\n",
    "    return adjRsquared,RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Adjusted R-squared and RMSE for Train',adjustedMetrics(Train,lm,9,'spy'))\n",
    "print('Adjusted R-squared and RMSE for Test',adjustedMetrics(Test,lm,9,'spy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assessTable(test,train,model,model_k,yname):\n",
    "    r2test,RMSEtest = adjustedMetrics(test,model,model_k,yname)\n",
    "    r2train,RMSEtrain = adjustedMetrics(train,model,model_k,yname)\n",
    "    assessment = pd.DataFrame(index=['R2','RMSE'],columns=['Train','Test'])\n",
    "    assessment['Train'] = [r2train,RMSEtrain]\n",
    "    assessment['Test'] = [r2test,RMSEtest]\n",
    "    return assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the assessment table for our model\n",
    "assessTable(Test,Train,lm,9,'spy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< [Notebook 14](PartIV3.ipynb) | [PyFinLab Index](ALWAYS-START-HERE.ipynb) | [Notebook 16](PartV2.ipynb) >\n",
    "\n",
    "<div align=\"right\"><a href=\"#ref00\">back to top</a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
